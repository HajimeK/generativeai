{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a108af04",
   "metadata": {},
   "source": [
    "# Personalized Rea Estate Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9decdfad",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up the Python Application\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "\n",
    "requirements.txt\n",
    "    langchain==0.1.12\n",
    "    openai==0.28.1\n",
    "    pydantic>=1.10.12\n",
    "    pytest>=7.4.0\n",
    "    sentence-transformers>=2.2.0\n",
    "    transformers>=4.31.0\n",
    "    chromadb==0.4.15\n",
    "    jupyter==1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1720c",
   "metadata": {},
   "source": [
    "Set OpenAI API key to environment variable so that langchain methods can refer them in the environment variables list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e20bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = open(\"../../api_keys/openai.key\", \"rt\").read()\n",
    "os.environ[\"openai_api_key\"] = openai_api_key\n",
    "OpenAI_CHAT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4f1819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key,\n",
    "            model_name=OpenAI_CHAT_MODEL,\n",
    "            temperature=0.6,\n",
    "            max_tokens=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be47368",
   "metadata": {},
   "source": [
    "## Step 3: Storing Listings in a Vector Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a2f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma DB packages\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b4390",
   "metadata": {},
   "source": [
    "Load it the dataset from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014d350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = CSVLoader(file_path='./experiences.csv')\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d01c9e",
   "metadata": {},
   "source": [
    "- **Vector Database Setup**: Initialize and configure ChromaDB or a similar vector database to store real estate listings.\n",
    "- **Generating and Storing Embeddings**: Convert the LLM-generated listings into suitable embeddings that capture the semantic content of each listing, and store these embeddings in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6dd64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#db = Chroma.from_documents(chunks, OpenAIEmbeddings())\n",
    "db = Chroma.from_documents(documents = split_docs,\n",
    "                        embedding = OpenAIEmbeddings(),\n",
    "                        persist_directory='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9e4cf",
   "metadata": {},
   "source": [
    "Test the vector db to extract the similarity entries to the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97daa7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Name: experiences\\nname.1: AIoT Streaming Analytics\\ntag: AIML\\nskill: Apama\\ndescription: Workshop to empower a partner ready for AIoT(AI+IoT) streaming analytics\\nURL: NA', metadata={'row': 38, 'source': './experiences.csv'}),\n",
       " Document(page_content='Name: experiences\\nname.1: AIoT Streaming Analytics\\ntag: AIML\\nskill: Cumulocity\\ndescription: Workshop to empower a partner ready for AIoT(AI+IoT) streaming analytics\\nURL: NA', metadata={'row': 39, 'source': './experiences.csv'}),\n",
       " Document(page_content='Name: experiences\\nname.1: AIoT Streaming Analytics\\ntag: IoT\\nskill: Apama\\ndescription: Workshop to empower a partner ready for AIoT(AI+IoT) streaming analytics\\nURL: NA', metadata={'row': 35, 'source': './experiences.csv'}),\n",
       " Document(page_content='Name: experiences\\nname.1: AIoT Streaming Analytics\\ntag: AIML\\nskill: Python\\ndescription: Workshop to empower a partner ready for AIoT(AI+IoT) streaming analytics\\nURL: NA', metadata={'row': 37, 'source': './experiences.csv'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_docs = db.similarity_search(\"AI related experiences\")\n",
    "matching_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24df7f2",
   "metadata": {},
   "source": [
    "Following is the test to use vector db with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7d568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Name: experiences\n",
      "name.1: Fleet IoT\n",
      "tag: AIML\n",
      "skill: Python\n",
      "description: Fleet solution packaging project targeting the Japanese market. Install in-vehicle devices and collect data from platforms. From on-site data collection, provided the scoring function of the driver's behavior data using ML methods (4 months)\n",
      "URL: NA\n",
      "\n",
      "Name: experiences\n",
      "name.1: Fleet IoT\n",
      "tag: AIML\n",
      "skill: Pandas\n",
      "description: Fleet solution packaging project targeting the Japanese market. Install in-vehicle devices and collect data from platforms. From on-site data collection, provided the scoring function of the driver's behavior data using ML methods (4 months)\n",
      "URL: NA\n",
      "\n",
      "Name: experiences\n",
      "name.1: Fleet IoT\n",
      "tag: AIML\n",
      "skill: SKLearn\n",
      "description: Fleet solution packaging project targeting the Japanese market. Install in-vehicle devices and collect data from platforms. From on-site data collection, provided the scoring function of the driver's behavior data using ML methods (4 months)\n",
      "URL: NA\n",
      "\n",
      "Name: experiences\n",
      "name.1: Fleet IoT\n",
      "tag: AIML\n",
      "skill: Jupyter\n",
      "description: Fleet solution packaging project targeting the Japanese market. Install in-vehicle devices and collect data from platforms. From on-site data collection, provided the scoring function of the driver's behavior data using ML methods (4 months)\n",
      "URL: NA\n",
      "Human: Which area is mostly worked?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the individual has mostly worked on a Fleet IoT project with a focus on Artificial Intelligence and Machine Learning (AIML) skills. They have experience in Python, Pandas, SKLearn, and Jupyter as part of this project. The main area of work seems to be developing a fleet solution for the Japanese market, involving the installation of in-vehicle devices, data collection from platforms, and providing a scoring function for driver behavior data using machine learning methods.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\",verbose=True)\n",
    "\n",
    "answer =  chain.run(input_documents=matching_docs, question=\"Which area is mostly worked?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0461ee",
   "metadata": {},
   "source": [
    "Another example with RetrievalQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e60be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The computer languages frequently experienced in the provided context are Python and Jupyter.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "retrieval_chain = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "retrieval_chain.run(\"Which computer language is frequently experienced?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5208c",
   "metadata": {},
   "source": [
    "## Step 4: Building the User Preference Interface\n",
    "\n",
    "Collect buyer preferences, such as the number of bedrooms, bathrooms, location, and other specific requirements from a set of questions or telling the buyer to enter their preferences in natural language. You can hard-code the buyer preferences in questions and answers as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012cb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "                \"Which role are you seeking for?\",\n",
    "                \"What are the technical strength you have obtained through your carier?\",\n",
    "                \"Which roles have you played?\",\n",
    "                \"What kind of teams have you lead?\",\n",
    "                \"Can you run business in English and Japanese\",\n",
    "            ]\n",
    "answers = [\n",
    "                \"An indivisual contributor role in AI and IoT area\",\n",
    "                \"I can work on wide range of IT skill from HW to business applications\",\n",
    "                \"Solution Engineer role and customer facing role in the tough situation\",\n",
    "                \"Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\",\n",
    "                \"Yes. I can communicat in both languages.\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b578b",
   "metadata": {},
   "source": [
    "Buyer Preference Parsing: Implement logic to interpret and structure these preferences for inputing the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73152180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ChatMessageHistory\n",
    "#from typing import Any, Dict, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdeb0e3",
   "metadata": {},
   "source": [
    "Create a memory of QAs for user preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "427ed1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a conversational history\n",
    "history = ChatMessageHistory()\n",
    "for question, answer in zip(questions, answers):\n",
    "    history.add_ai_message(question)\n",
    "    history.add_user_message(answer)\n",
    "history.add_ai_message(\"\"\"Now I can recommend you a job we're considering best suited for you.\"\"\")\n",
    "\n",
    "# you could choose to store some of the q/a in memory as well, in addition to original questions\n",
    "# class MementoBufferMemory(ConversationBufferMemory):\n",
    "#     def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "#         input_str, output_str = self._get_input_output(inputs, outputs)\n",
    "#         self.chat_memory.add_user_message(input_str)\n",
    "#         self.chat_memory.add_ai_message(output_str)\n",
    "\n",
    "preset_memory = ConversationBufferMemory(\n",
    "    chat_memory=history,\n",
    "    memory_key = 'chat_history',\n",
    "    return_messages=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ad6f7",
   "metadata": {},
   "source": [
    "Create a chain to make a recommendation based on QA conversation memory and listings the agent has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"\n",
    "Answer the question as precisely and accurately based on the context below\n",
    "{context}\n",
    "Question: {question}\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"])\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e699c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm,\n",
    "    retriever =db.as_retriever(),\n",
    "    memory=preset_memory,\n",
    "    combine_docs_chain_kwargs=chain_type_kwargs,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a09ba6",
   "metadata": {},
   "source": [
    "Test with an example inquirry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f5966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Assistant: Which role are you seeking for?\n",
      "Human: An indivisual contributor role in AI and IoT area\n",
      "Assistant: What are the technical strength you have obtained through your carier?\n",
      "Human: I can work on wide range of IT skill from HW to business applications\n",
      "Assistant: Which roles have you played?\n",
      "Human: Solution Engineer role and customer facing role in the tough situation\n",
      "Assistant: What kind of teams have you lead?\n",
      "Human: Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\n",
      "Assistant: Can you run business in English and Japanese\n",
      "Human: Yes. I can communicat in both languages.\n",
      "Assistant: Now I can recommend you a job we're considering best suited for you.\n",
      "Follow Up Input: Considering my background, what kind of job fits to me?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Answer the question as precisely and accurately based on the context below\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: SKLearn\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Jupyter\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Pandas\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Python\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "Question: What kind of job fits to me considering my background?\n",
      "Chat History:\n",
      "\n",
      "Assistant: Which role are you seeking for?\n",
      "Human: An indivisual contributor role in AI and IoT area\n",
      "Assistant: What are the technical strength you have obtained through your carier?\n",
      "Human: I can work on wide range of IT skill from HW to business applications\n",
      "Assistant: Which roles have you played?\n",
      "Human: Solution Engineer role and customer facing role in the tough situation\n",
      "Assistant: What kind of teams have you lead?\n",
      "Human: Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\n",
      "Assistant: Can you run business in English and Japanese\n",
      "Human: Yes. I can communicat in both languages.\n",
      "Assistant: Now I can recommend you a job we're considering best suited for you.\n",
      "Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = qa.invoke(\"Considering my background, what kind of job fits to me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f589a",
   "metadata": {},
   "source": [
    "Display the response(answer) from AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c28e97a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cada282",
   "metadata": {},
   "source": [
    "## Step 6: Test with an app\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ae15e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Assistant: Which role are you seeking for?\n",
      "Human: An indivisual contributor role in AI and IoT area\n",
      "Assistant: What are the technical strength you have obtained through your carier?\n",
      "Human: I can work on wide range of IT skill from HW to business applications\n",
      "Assistant: Which roles have you played?\n",
      "Human: Solution Engineer role and customer facing role in the tough situation\n",
      "Assistant: What kind of teams have you lead?\n",
      "Human: Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\n",
      "Assistant: Can you run business in English and Japanese\n",
      "Human: Yes. I can communicat in both languages.\n",
      "Assistant: Now I can recommend you a job we're considering best suited for you.\n",
      "Human: Considering my background, what kind of job fits to me?\n",
      "Assistant: Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.\n",
      "Follow Up Input: Which company is good for me to work?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Answer the question as precisely and accurately based on the context below\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: SKLearn\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Jupyter\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Pandas\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Consumer Project IoT\n",
      "tag: IoT\n",
      "skill: Jupyter\n",
      "description: As an engineer in a PoC to make customer product ready for IoT. Technology lead in defining subsequent commercialization requirements (1.5 year)\n",
      "URL: NA\n",
      "Question: Which company would be a good fit for me to work based on my background and skills?\n",
      "Chat History:\n",
      "\n",
      "Assistant: Which role are you seeking for?\n",
      "Human: An indivisual contributor role in AI and IoT area\n",
      "Assistant: What are the technical strength you have obtained through your carier?\n",
      "Human: I can work on wide range of IT skill from HW to business applications\n",
      "Assistant: Which roles have you played?\n",
      "Human: Solution Engineer role and customer facing role in the tough situation\n",
      "Assistant: What kind of teams have you lead?\n",
      "Human: Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\n",
      "Assistant: Can you run business in English and Japanese\n",
      "Human: Yes. I can communicat in both languages.\n",
      "Assistant: Now I can recommend you a job we're considering best suited for you.\n",
      "Human: Considering my background, what kind of job fits to me?\n",
      "Assistant: Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.\n",
      "Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Assistant: Which role are you seeking for?\n",
      "Human: An indivisual contributor role in AI and IoT area\n",
      "Assistant: What are the technical strength you have obtained through your carier?\n",
      "Human: I can work on wide range of IT skill from HW to business applications\n",
      "Assistant: Which roles have you played?\n",
      "Human: Solution Engineer role and customer facing role in the tough situation\n",
      "Assistant: What kind of teams have you lead?\n",
      "Human: Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\n",
      "Assistant: Can you run business in English and Japanese\n",
      "Human: Yes. I can communicat in both languages.\n",
      "Assistant: Now I can recommend you a job we're considering best suited for you.\n",
      "Human: Considering my background, what kind of job fits to me?\n",
      "Assistant: Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.\n",
      "Human: Which company is good for me to work?\n",
      "Assistant: Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.\n",
      "Follow Up Input: Can you name a few which focuses on that area?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Answer the question as precisely and accurately based on the context below\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: SKLearn\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Pandas\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Jupyter\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "\n",
      "Name: experiences\n",
      "name.1: Azure ML with real data\n",
      "tag: AIML\n",
      "skill: Python\n",
      "description: Using an traditional census data in Machine Learning studies, here I have derived prediction models to find potential donors. If the income is expected larger than 50K, we find the person as potential donors and put emphasis on the activity to ask for donations.\n",
      "URL: https://github.com/HajimeK/nd00333-capstone\n",
      "Question: Which companies focus on AI, machine learning, and data science that you would recommend for someone with your background and skills?\n",
      "Chat History:\n",
      "\n",
      "Assistant: Which role are you seeking for?\n",
      "Human: An indivisual contributor role in AI and IoT area\n",
      "Assistant: What are the technical strength you have obtained through your carier?\n",
      "Human: I can work on wide range of IT skill from HW to business applications\n",
      "Assistant: Which roles have you played?\n",
      "Human: Solution Engineer role and customer facing role in the tough situation\n",
      "Assistant: What kind of teams have you lead?\n",
      "Human: Team consist of member from diverse areas and roles in the world. India, US, Europe, China. Product Managers, devlopers and etc.\n",
      "Assistant: Can you run business in English and Japanese\n",
      "Human: Yes. I can communicat in both languages.\n",
      "Assistant: Now I can recommend you a job we're considering best suited for you.\n",
      "Human: Considering my background, what kind of job fits to me?\n",
      "Assistant: Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.\n",
      "Human: Which company is good for me to work?\n",
      "Assistant: Based on your background and skills in IT, AI, and IoT, as well as your experience as a Solution Engineer and leading diverse teams, a role as a Data Scientist or Machine Learning Engineer could be a good fit for you. Your experience with Azure ML, SKLearn, Jupyter, Pandas, and Python, as well as your ability to communicate in English and Japanese, make you well-suited for roles that involve working with data, developing prediction models, and implementing AI solutions. Consider exploring opportunities in companies that focus on AI, machine learning, and data science.\n",
      "Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio\n",
    "\n",
    "def runChain(query, history):\n",
    "    return qa(query)[\"answer\"]\n",
    "\n",
    "app = gradio.ChatInterface(runChain)\n",
    "app.queue()\n",
    "app.launch(share=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5777ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9eb4b",
   "metadata": {},
   "source": [
    "## Sample chat app output\n",
    "\n",
    "![chat app](./chatapp.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
